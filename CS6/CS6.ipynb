{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91659aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "086ac320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># label</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>...</th>\n",
       "      <th>f18</th>\n",
       "      <th>f19</th>\n",
       "      <th>f20</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>mass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.346368</td>\n",
       "      <td>0.416306</td>\n",
       "      <td>0.999236</td>\n",
       "      <td>0.475342</td>\n",
       "      <td>0.427493</td>\n",
       "      <td>-0.005984</td>\n",
       "      <td>1.989833</td>\n",
       "      <td>0.344530</td>\n",
       "      <td>1.566297</td>\n",
       "      <td>...</td>\n",
       "      <td>4.105282</td>\n",
       "      <td>0.267826</td>\n",
       "      <td>0.378718</td>\n",
       "      <td>1.743123</td>\n",
       "      <td>3.406367</td>\n",
       "      <td>4.350537</td>\n",
       "      <td>-0.352571</td>\n",
       "      <td>1.130032</td>\n",
       "      <td>2.227706</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.708236</td>\n",
       "      <td>-0.319394</td>\n",
       "      <td>-1.241873</td>\n",
       "      <td>-0.887231</td>\n",
       "      <td>-0.871906</td>\n",
       "      <td>-0.005984</td>\n",
       "      <td>-0.001047</td>\n",
       "      <td>-1.038225</td>\n",
       "      <td>0.655748</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.178141</td>\n",
       "      <td>-0.877361</td>\n",
       "      <td>-1.483769</td>\n",
       "      <td>-0.573682</td>\n",
       "      <td>-1.693781</td>\n",
       "      <td>-0.545062</td>\n",
       "      <td>-0.299118</td>\n",
       "      <td>-0.662942</td>\n",
       "      <td>-0.193019</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.360693</td>\n",
       "      <td>1.794174</td>\n",
       "      <td>0.264738</td>\n",
       "      <td>-0.472273</td>\n",
       "      <td>-0.292344</td>\n",
       "      <td>-1.054221</td>\n",
       "      <td>-1.150495</td>\n",
       "      <td>1.423404</td>\n",
       "      <td>1.270098</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.199511</td>\n",
       "      <td>0.539020</td>\n",
       "      <td>-1.590629</td>\n",
       "      <td>-0.573682</td>\n",
       "      <td>-0.543636</td>\n",
       "      <td>-0.937456</td>\n",
       "      <td>-0.300344</td>\n",
       "      <td>-0.523262</td>\n",
       "      <td>-1.506304</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.377914</td>\n",
       "      <td>-0.103932</td>\n",
       "      <td>-0.649434</td>\n",
       "      <td>-2.125015</td>\n",
       "      <td>-1.643797</td>\n",
       "      <td>-0.005984</td>\n",
       "      <td>1.011112</td>\n",
       "      <td>-1.040340</td>\n",
       "      <td>-0.541991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463763</td>\n",
       "      <td>-0.006583</td>\n",
       "      <td>1.089122</td>\n",
       "      <td>-0.573682</td>\n",
       "      <td>-0.276348</td>\n",
       "      <td>-0.409272</td>\n",
       "      <td>-0.349926</td>\n",
       "      <td>-0.307123</td>\n",
       "      <td>0.529698</td>\n",
       "      <td>1250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.067436</td>\n",
       "      <td>-0.636762</td>\n",
       "      <td>-0.620166</td>\n",
       "      <td>-0.062551</td>\n",
       "      <td>1.588715</td>\n",
       "      <td>-0.005984</td>\n",
       "      <td>-0.595304</td>\n",
       "      <td>-1.238987</td>\n",
       "      <td>0.336844</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.552837</td>\n",
       "      <td>-1.418494</td>\n",
       "      <td>-0.562982</td>\n",
       "      <td>1.743123</td>\n",
       "      <td>0.881802</td>\n",
       "      <td>0.002516</td>\n",
       "      <td>1.560950</td>\n",
       "      <td>-0.150760</td>\n",
       "      <td>-1.023889</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   # label        f0        f1        f2        f3        f4        f5  \\\n",
       "0      1.0 -0.346368  0.416306  0.999236  0.475342  0.427493 -0.005984   \n",
       "1      1.0  1.708236 -0.319394 -1.241873 -0.887231 -0.871906 -0.005984   \n",
       "2      0.0 -0.360693  1.794174  0.264738 -0.472273 -0.292344 -1.054221   \n",
       "3      1.0 -0.377914 -0.103932 -0.649434 -2.125015 -1.643797 -0.005984   \n",
       "4      0.0 -0.067436 -0.636762 -0.620166 -0.062551  1.588715 -0.005984   \n",
       "\n",
       "         f6        f7        f8  ...       f18       f19       f20       f21  \\\n",
       "0  1.989833  0.344530  1.566297  ...  4.105282  0.267826  0.378718  1.743123   \n",
       "1 -0.001047 -1.038225  0.655748  ... -1.178141 -0.877361 -1.483769 -0.573682   \n",
       "2 -1.150495  1.423404  1.270098  ... -1.199511  0.539020 -1.590629 -0.573682   \n",
       "3  1.011112 -1.040340 -0.541991  ...  0.463763 -0.006583  1.089122 -0.573682   \n",
       "4 -0.595304 -1.238987  0.336844  ... -0.552837 -1.418494 -0.562982  1.743123   \n",
       "\n",
       "        f22       f23       f24       f25       f26    mass  \n",
       "0  3.406367  4.350537 -0.352571  1.130032  2.227706  1000.0  \n",
       "1 -1.693781 -0.545062 -0.299118 -0.662942 -0.193019   750.0  \n",
       "2 -0.543636 -0.937456 -0.300344 -0.523262 -1.506304   750.0  \n",
       "3 -0.276348 -0.409272 -0.349926 -0.307123  0.529698  1250.0  \n",
       "4  0.881802  0.002516  1.560950 -0.150760 -1.023889   750.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/austi/Documents/QTW/Case Study 6/all_train.csv.gz', compression='gzip')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e73f8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># label</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>...</th>\n",
       "      <th>f18</th>\n",
       "      <th>f19</th>\n",
       "      <th>f20</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>mass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.346368</td>\n",
       "      <td>0.416306</td>\n",
       "      <td>0.999236</td>\n",
       "      <td>0.475342</td>\n",
       "      <td>0.427493</td>\n",
       "      <td>-0.005984</td>\n",
       "      <td>1.989833</td>\n",
       "      <td>0.344530</td>\n",
       "      <td>1.566297</td>\n",
       "      <td>...</td>\n",
       "      <td>4.105282</td>\n",
       "      <td>0.267826</td>\n",
       "      <td>0.378718</td>\n",
       "      <td>1.743123</td>\n",
       "      <td>3.406367</td>\n",
       "      <td>4.350537</td>\n",
       "      <td>-0.352571</td>\n",
       "      <td>1.130032</td>\n",
       "      <td>2.227706</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.708236</td>\n",
       "      <td>-0.319394</td>\n",
       "      <td>-1.241873</td>\n",
       "      <td>-0.887231</td>\n",
       "      <td>-0.871906</td>\n",
       "      <td>-0.005984</td>\n",
       "      <td>-0.001047</td>\n",
       "      <td>-1.038225</td>\n",
       "      <td>0.655748</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.178141</td>\n",
       "      <td>-0.877361</td>\n",
       "      <td>-1.483769</td>\n",
       "      <td>-0.573682</td>\n",
       "      <td>-1.693781</td>\n",
       "      <td>-0.545062</td>\n",
       "      <td>-0.299118</td>\n",
       "      <td>-0.662942</td>\n",
       "      <td>-0.193019</td>\n",
       "      <td>750.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.360693</td>\n",
       "      <td>1.794174</td>\n",
       "      <td>0.264738</td>\n",
       "      <td>-0.472273</td>\n",
       "      <td>-0.292344</td>\n",
       "      <td>-1.054221</td>\n",
       "      <td>-1.150495</td>\n",
       "      <td>1.423404</td>\n",
       "      <td>1.270098</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.199511</td>\n",
       "      <td>0.539020</td>\n",
       "      <td>-1.590629</td>\n",
       "      <td>-0.573682</td>\n",
       "      <td>-0.543636</td>\n",
       "      <td>-0.937456</td>\n",
       "      <td>-0.300344</td>\n",
       "      <td>-0.523262</td>\n",
       "      <td>-1.506304</td>\n",
       "      <td>750.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.377914</td>\n",
       "      <td>-0.103932</td>\n",
       "      <td>-0.649434</td>\n",
       "      <td>-2.125015</td>\n",
       "      <td>-1.643797</td>\n",
       "      <td>-0.005984</td>\n",
       "      <td>1.011112</td>\n",
       "      <td>-1.040340</td>\n",
       "      <td>-0.541991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463763</td>\n",
       "      <td>-0.006583</td>\n",
       "      <td>1.089122</td>\n",
       "      <td>-0.573682</td>\n",
       "      <td>-0.276348</td>\n",
       "      <td>-0.409272</td>\n",
       "      <td>-0.349926</td>\n",
       "      <td>-0.307123</td>\n",
       "      <td>0.529698</td>\n",
       "      <td>1250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.067436</td>\n",
       "      <td>-0.636762</td>\n",
       "      <td>-0.620166</td>\n",
       "      <td>-0.062551</td>\n",
       "      <td>1.588715</td>\n",
       "      <td>-0.005984</td>\n",
       "      <td>-0.595304</td>\n",
       "      <td>-1.238987</td>\n",
       "      <td>0.336844</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.552837</td>\n",
       "      <td>-1.418494</td>\n",
       "      <td>-0.562982</td>\n",
       "      <td>1.743123</td>\n",
       "      <td>0.881802</td>\n",
       "      <td>0.002516</td>\n",
       "      <td>1.560950</td>\n",
       "      <td>-0.150760</td>\n",
       "      <td>-1.023889</td>\n",
       "      <td>750.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.617264</td>\n",
       "      <td>-0.537084</td>\n",
       "      <td>-1.275867</td>\n",
       "      <td>0.650799</td>\n",
       "      <td>-1.511621</td>\n",
       "      <td>0.850488</td>\n",
       "      <td>0.596391</td>\n",
       "      <td>-0.054678</td>\n",
       "      <td>0.728849</td>\n",
       "      <td>...</td>\n",
       "      <td>0.664328</td>\n",
       "      <td>-0.960709</td>\n",
       "      <td>-0.894011</td>\n",
       "      <td>1.743123</td>\n",
       "      <td>-0.426198</td>\n",
       "      <td>-0.324286</td>\n",
       "      <td>-0.432739</td>\n",
       "      <td>1.340297</td>\n",
       "      <td>0.267774</td>\n",
       "      <td>750.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.511357</td>\n",
       "      <td>0.270927</td>\n",
       "      <td>0.085989</td>\n",
       "      <td>-0.243802</td>\n",
       "      <td>-1.035668</td>\n",
       "      <td>-0.005984</td>\n",
       "      <td>-0.127219</td>\n",
       "      <td>0.721426</td>\n",
       "      <td>1.404479</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.015462</td>\n",
       "      <td>1.367217</td>\n",
       "      <td>-1.053815</td>\n",
       "      <td>-0.573682</td>\n",
       "      <td>-1.907798</td>\n",
       "      <td>0.194661</td>\n",
       "      <td>-0.190621</td>\n",
       "      <td>0.027776</td>\n",
       "      <td>-0.316018</td>\n",
       "      <td>1250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.062408</td>\n",
       "      <td>-0.987203</td>\n",
       "      <td>0.570667</td>\n",
       "      <td>1.517195</td>\n",
       "      <td>0.639548</td>\n",
       "      <td>-1.054221</td>\n",
       "      <td>1.115239</td>\n",
       "      <td>1.261928</td>\n",
       "      <td>-1.009308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790842</td>\n",
       "      <td>0.892545</td>\n",
       "      <td>-0.192816</td>\n",
       "      <td>-0.573682</td>\n",
       "      <td>0.973622</td>\n",
       "      <td>1.034964</td>\n",
       "      <td>-0.340661</td>\n",
       "      <td>-0.181193</td>\n",
       "      <td>1.877042</td>\n",
       "      <td>1500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.659131</td>\n",
       "      <td>1.096223</td>\n",
       "      <td>0.562821</td>\n",
       "      <td>1.627193</td>\n",
       "      <td>0.767236</td>\n",
       "      <td>-1.054221</td>\n",
       "      <td>1.079999</td>\n",
       "      <td>0.155488</td>\n",
       "      <td>-1.412207</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.671423</td>\n",
       "      <td>-0.308908</td>\n",
       "      <td>-0.568336</td>\n",
       "      <td>-0.573682</td>\n",
       "      <td>1.043119</td>\n",
       "      <td>1.270350</td>\n",
       "      <td>0.217405</td>\n",
       "      <td>0.120213</td>\n",
       "      <td>1.073020</td>\n",
       "      <td>1500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.744152</td>\n",
       "      <td>-0.908839</td>\n",
       "      <td>-0.770454</td>\n",
       "      <td>1.008405</td>\n",
       "      <td>-1.054221</td>\n",
       "      <td>-0.370155</td>\n",
       "      <td>0.296837</td>\n",
       "      <td>-1.492524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.352893</td>\n",
       "      <td>0.671047</td>\n",
       "      <td>0.176512</td>\n",
       "      <td>-0.573682</td>\n",
       "      <td>0.314739</td>\n",
       "      <td>0.304983</td>\n",
       "      <td>0.425471</td>\n",
       "      <td>-0.612085</td>\n",
       "      <td>-0.925097</td>\n",
       "      <td>499.999969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000000 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         # label        f0        f1        f2        f3        f4        f5  \\\n",
       "0            1.0 -0.346368  0.416306  0.999236  0.475342  0.427493 -0.005984   \n",
       "1            1.0  1.708236 -0.319394 -1.241873 -0.887231 -0.871906 -0.005984   \n",
       "2            0.0 -0.360693  1.794174  0.264738 -0.472273 -0.292344 -1.054221   \n",
       "3            1.0 -0.377914 -0.103932 -0.649434 -2.125015 -1.643797 -0.005984   \n",
       "4            0.0 -0.067436 -0.636762 -0.620166 -0.062551  1.588715 -0.005984   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "6999995      0.0  1.617264 -0.537084 -1.275867  0.650799 -1.511621  0.850488   \n",
       "6999996      0.0 -0.511357  0.270927  0.085989 -0.243802 -1.035668 -0.005984   \n",
       "6999997      1.0  0.062408 -0.987203  0.570667  1.517195  0.639548 -1.054221   \n",
       "6999998      1.0  1.659131  1.096223  0.562821  1.627193  0.767236 -1.054221   \n",
       "6999999      1.0  0.002034  0.744152 -0.908839 -0.770454  1.008405 -1.054221   \n",
       "\n",
       "               f6        f7        f8  ...       f18       f19       f20  \\\n",
       "0        1.989833  0.344530  1.566297  ...  4.105282  0.267826  0.378718   \n",
       "1       -0.001047 -1.038225  0.655748  ... -1.178141 -0.877361 -1.483769   \n",
       "2       -1.150495  1.423404  1.270098  ... -1.199511  0.539020 -1.590629   \n",
       "3        1.011112 -1.040340 -0.541991  ...  0.463763 -0.006583  1.089122   \n",
       "4       -0.595304 -1.238987  0.336844  ... -0.552837 -1.418494 -0.562982   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "6999995  0.596391 -0.054678  0.728849  ...  0.664328 -0.960709 -0.894011   \n",
       "6999996 -0.127219  0.721426  1.404479  ... -1.015462  1.367217 -1.053815   \n",
       "6999997  1.115239  1.261928 -1.009308  ...  0.790842  0.892545 -0.192816   \n",
       "6999998  1.079999  0.155488 -1.412207  ... -0.671423 -0.308908 -0.568336   \n",
       "6999999 -0.370155  0.296837 -1.492524  ...  0.352893  0.671047  0.176512   \n",
       "\n",
       "              f21       f22       f23       f24       f25       f26  \\\n",
       "0        1.743123  3.406367  4.350537 -0.352571  1.130032  2.227706   \n",
       "1       -0.573682 -1.693781 -0.545062 -0.299118 -0.662942 -0.193019   \n",
       "2       -0.573682 -0.543636 -0.937456 -0.300344 -0.523262 -1.506304   \n",
       "3       -0.573682 -0.276348 -0.409272 -0.349926 -0.307123  0.529698   \n",
       "4        1.743123  0.881802  0.002516  1.560950 -0.150760 -1.023889   \n",
       "...           ...       ...       ...       ...       ...       ...   \n",
       "6999995  1.743123 -0.426198 -0.324286 -0.432739  1.340297  0.267774   \n",
       "6999996 -0.573682 -1.907798  0.194661 -0.190621  0.027776 -0.316018   \n",
       "6999997 -0.573682  0.973622  1.034964 -0.340661 -0.181193  1.877042   \n",
       "6999998 -0.573682  1.043119  1.270350  0.217405  0.120213  1.073020   \n",
       "6999999 -0.573682  0.314739  0.304983  0.425471 -0.612085 -0.925097   \n",
       "\n",
       "                mass  \n",
       "0        1000.000000  \n",
       "1         750.000000  \n",
       "2         750.000000  \n",
       "3        1250.000000  \n",
       "4         750.000000  \n",
       "...              ...  \n",
       "6999995   750.000000  \n",
       "6999996  1250.000000  \n",
       "6999997  1500.000000  \n",
       "6999998  1500.000000  \n",
       "6999999   499.999969  \n",
       "\n",
       "[7000000 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9387117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# label\n",
       "1.0    3500879\n",
       "0.0    3499121\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['# label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9beba665",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_column_name = '# label'  \n",
    "\n",
    "X = df.drop(columns=[label_column_name])\n",
    "y = df[label_column_name].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_test, y_test, test_size = 0.5, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1908d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "60a1ffc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "87500/87500 [==============================] - 219s 2ms/step - loss: 0.2916 - accuracy: 0.8663 - val_loss: 565.1225 - val_accuracy: 0.4990\n",
      "Epoch 2/20\n",
      "87500/87500 [==============================] - 231s 3ms/step - loss: 0.2828 - accuracy: 0.8717 - val_loss: 641.2617 - val_accuracy: 0.4990\n",
      "Epoch 3/20\n",
      "87500/87500 [==============================] - 225s 3ms/step - loss: 0.2809 - accuracy: 0.8729 - val_loss: 692.3073 - val_accuracy: 0.4990\n",
      "Epoch 4/20\n",
      "87500/87500 [==============================] - 225s 3ms/step - loss: 0.2799 - accuracy: 0.8734 - val_loss: 495.6862 - val_accuracy: 0.4990\n",
      "Epoch 5/20\n",
      "87500/87500 [==============================] - 225s 3ms/step - loss: 0.2791 - accuracy: 0.8738 - val_loss: 414.4282 - val_accuracy: 0.4990\n",
      "Epoch 6/20\n",
      "87500/87500 [==============================] - 226s 3ms/step - loss: 0.2787 - accuracy: 0.8741 - val_loss: 420.0512 - val_accuracy: 0.4990\n",
      "Epoch 7/20\n",
      "87500/87500 [==============================] - 226s 3ms/step - loss: 0.2783 - accuracy: 0.8744 - val_loss: 629.4340 - val_accuracy: 0.4990\n",
      "Epoch 8/20\n",
      "87500/87500 [==============================] - 232s 3ms/step - loss: 0.2780 - accuracy: 0.8747 - val_loss: 545.2984 - val_accuracy: 0.4990\n",
      "Epoch 9/20\n",
      "87500/87500 [==============================] - 225s 3ms/step - loss: 0.2777 - accuracy: 0.8747 - val_loss: 895.1238 - val_accuracy: 0.4990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x145cb91abb0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# takes ~20 min\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 4)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape = (X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),  \n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(1, activation = 'sigmoid') # sigmoidd is good for binary clasification\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer = 'adam', \n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(X_train, \n",
    "          y_train,\n",
    "          epochs = 20,\n",
    "          batch_size = 64,\n",
    "          callbacks = [callback], \n",
    "          validation_data = (X_validation, y_validation))\n",
    "\n",
    "# accuracy maintains around 87% in the first epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9e4a9d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21875/21875 [==============================] - 27s 1ms/step - loss: 0.2717 - accuracy: 0.8797\n",
      "Test Accuracy: 87.97%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906616a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "78060dc6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_20 (Dense)            (None, 128)               3712      \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,545\n",
      "Trainable params: 28,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3800b818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21875/21875 [==============================] - 24s 1ms/step\n",
      "Confusion Matrix:\n",
      "[[300642  49207]\n",
      " [ 35028 315123]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.round(y_pred).flatten()\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e05d6660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(conf_matrix, \n",
    "            annot = True,\n",
    "            fmt = 'd',\n",
    "            cmap = 'Blues',\n",
    "            cbar = False,\n",
    "            xticklabels = ['0', '1'],\n",
    "            yticklabels = ['0', '1'])\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6093c20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Should we train a random forest like capstone then run again on best features??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
